{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and load necesary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>298</td>\n",
       "      <td>474</td>\n",
       "      <td>4</td>\n",
       "      <td>884182806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>115</td>\n",
       "      <td>265</td>\n",
       "      <td>2</td>\n",
       "      <td>881171488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>253</td>\n",
       "      <td>465</td>\n",
       "      <td>5</td>\n",
       "      <td>891628467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating  timestamp\n",
       "1      186      302       3  891717742\n",
       "3      244       51       2  880606923\n",
       "5      298      474       4  884182806\n",
       "6      115      265       2  881171488\n",
       "7      253      465       5  891628467"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "df = pd.read_csv('ml-100k/u.data', names=['user_id', 'item_id', 'rating', 'timestamp'], sep='\\t')\n",
    "\n",
    "# obtain top 500 users and top 500 items\n",
    "user_ids = df.groupby('user_id').count().sort_values(by='rating', ascending=False).head(500).index\n",
    "item_ids = df.groupby('item_id').count().sort_values(by='rating', ascending=False).head(500).index\n",
    "df = df[(df['user_id'].isin(user_ids)) & (df['item_id'].isin(item_ids))]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomly select one rating from each user as test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "# remap user and item ID\n",
    "df['user_id'] = df.groupby('user_id').ngroup()\n",
    "df['item_id'] = df.groupby('item_id').ngroup()\n",
    "\n",
    "test_df = df.groupby('user_id').sample(1, random_state=1024)\n",
    "train_df = df[~df.index.isin(test_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of users: 500\n",
      "The number of items: 500\n",
      "Avg. # of rated Items/User: 129.914\n",
      "Density of data: 0.259828\n",
      "Ratings Range: 1 - 5\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "n_users = df.user_id.unique().shape[0]\n",
    "n_items = df.item_id.unique().shape[0]\n",
    "avg_num = df.groupby('user_id').size().mean()\n",
    "density = df.shape[0] / (n_users * n_items)\n",
    "min_ratings = df.rating.min()\n",
    "max_ratings = df.rating.max()\n",
    "\n",
    "print(\"The number of users: {}\" .format(n_users))\n",
    "print(\"The number of items: {}\" .format(n_items))\n",
    "print(\"Avg. # of rated Items/User: {}\" .format(avg_num))\n",
    "print(\"Density of data: {}\" .format(density))\n",
    "print(\"Ratings Range: {} - {}\" .format(min_ratings, max_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Construct the rating matrix based on train_df:\n",
      "[[5. 3. 4. ... 0. 0. 0.]\n",
      " [4. 0. 0. ... 0. 0. 0.]\n",
      " [4. 3. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 5. 0. ... 0. 4. 0.]]\n",
      "Construct the rating matrix based on test_df:\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "# Convert the format of datasets to matrices\n",
    "# Train dataset\n",
    "df_zeros = pd.DataFrame({\n",
    "    'user_id': np.tile(np.arange(0, n_users), n_items), \n",
    "    'item_id': np.repeat(np.arange(0, n_items), n_users), \n",
    "    'rating': 0})\n",
    "train_ds = df_zeros.merge(train_df, \n",
    "                          how='left', \n",
    "                          on=['user_id', 'item_id']).fillna(0.).pivot_table(\n",
    "                              values='rating_y', \n",
    "                              index='user_id', \n",
    "                              columns='item_id').values\n",
    "                           \n",
    "# Test dataset\n",
    "test_ds = df_zeros.merge(test_df, \n",
    "                         how='left', \n",
    "                         on=['user_id', 'item_id']).fillna(0.).pivot_table(\n",
    "                             values='rating_y', \n",
    "                             index='user_id', \n",
    "                             columns='item_id').values\n",
    "\n",
    "print(\"Construct the rating matrix based on train_df:\")\n",
    "print(train_ds)\n",
    "\n",
    "print(\"Construct the rating matrix based on test_df:\")\n",
    "print(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "EPSILON = 1e-9\n",
    "\n",
    "def user_corr(imputed_train_ds):\n",
    "    '''\n",
    "    Function for calculating user's similarity\n",
    "    '''\n",
    "    active_user_pearson_corr = np.zeros((imputed_train_ds.shape[0], imputed_train_ds.shape[0]))\n",
    "\n",
    "    # Compute Pearson Correlation Coefficient of All Pairs of Users between active set and training dataset\n",
    "    for i, user_i_vec in enumerate(imputed_train_ds):\n",
    "        for j, user_j_vec in enumerate(imputed_train_ds):\n",
    "\n",
    "            # ratings corated by the current pair od users\n",
    "            mask_i = user_i_vec > 0\n",
    "            mask_j = user_j_vec > 0\n",
    "\n",
    "            # corrated item index, skip if there are no corrated ratings\n",
    "            corrated_index = np.intersect1d(np.where(mask_i), np.where(mask_j))\n",
    "            if len(corrated_index) == 0:\n",
    "                continue\n",
    "\n",
    "            # average value of user_i_vec and user_j_vec\n",
    "            mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "            mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "\n",
    "            # compute pearson corr\n",
    "            user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "            user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "            r_ui_sub_r_i_sq = np.square(user_i_sub_mean)\n",
    "            r_uj_sub_r_j_sq = np.square(user_j_sub_mean)\n",
    "\n",
    "            r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "            r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "            sim = np.sum(user_i_sub_mean * user_j_sub_mean) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "            active_user_pearson_corr[i][j] = sim\n",
    "\n",
    "    return active_user_pearson_corr\n",
    "\n",
    "def predict(test_ds, imputed_train_ds, user_corr, k=20):\n",
    "    '''\n",
    "    Function for predicting ratings in test_ds\n",
    "    '''\n",
    "\n",
    "    # Predicting ratings of test set\n",
    "    predicted_ds = np.zeros_like(test_ds)\n",
    "\n",
    "    for (i, j), rating in np.ndenumerate(test_ds):\n",
    "\n",
    "        if rating > 0:\n",
    "\n",
    "            # only predict ratings on test set\n",
    "            sim_user_ids = np.argsort(user_corr[i])[-1:-(k + 1):-1]\n",
    "\n",
    "            #==================user-based==================#\n",
    "            # the coefficient values of similar users\n",
    "            sim_val = user_corr[i][sim_user_ids]\n",
    "\n",
    "            # the average value of the current user's ratings\n",
    "            sim_users = imputed_train_ds[sim_user_ids]\n",
    "            \n",
    "            mask_rateditem_user = imputed_train_ds[i] != 0\n",
    "            num_rated_items = mask_rateditem_user.astype(np.float32)\n",
    "            user_mean = np.sum(imputed_train_ds[i, mask_rateditem_user]) / (num_rated_items.sum() + EPSILON)\n",
    "\n",
    "            mask_nei_rated_items = sim_users != 0\n",
    "            num_rated_per_user = mask_nei_rated_items.astype(np.float32)\n",
    "            num_per_user = num_rated_per_user.sum(axis=1)\n",
    "\n",
    "            sum_per_user = sim_users.sum(axis=1)\n",
    "            sim_user_mean = sum_per_user / (num_per_user + EPSILON)\n",
    "            \n",
    "            mask_rated_j = sim_users[:, j] > 0\n",
    "                            \n",
    "            # sim(u, v) * (r_vj - mean_v)\n",
    "            sim_r_sum_mean = sim_val[mask_rated_j] * (sim_users[mask_rated_j, j] - sim_user_mean[mask_rated_j])\n",
    "            \n",
    "            user_based_pred = user_mean + np.sum(sim_r_sum_mean) / (np.sum(sim_val[mask_rated_j]) + EPSILON)\n",
    "\n",
    "            predicted_ds[i, j] = np.clip(user_based_pred, 0, 5)\n",
    "            \n",
    "    return predicted_ds\n",
    "\n",
    "def evaluate(test_ds, predicted_ds):\n",
    "    '''\n",
    "    Function for evaluating on MAE and RMSE\n",
    "    '''\n",
    "    # MAE\n",
    "    mask_test_ds = test_ds > 0\n",
    "    MAE = np.sum(np.abs(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32))\n",
    "\n",
    "    # RMSE\n",
    "    RMSE = np.sqrt(np.sum(np.square(test_ds[mask_test_ds] - predicted_ds[mask_test_ds])) / np.sum(mask_test_ds.astype(np.float32)))\n",
    "\n",
    "    return MAE, RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline - KNN based recommendation (Similarity Metric: Pearson Correlation Coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "user_pearson_corr = user_corr(train_ds)\n",
    "predicted_ds = predict(test_ds, train_ds, user_pearson_corr, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== Baseline Result =====================\n",
      "MAE: 0.8471711011333851, RMSE: 1.092846045041526\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "MAE1, RMSE = evaluate(test_ds, predicted_ds)\n",
    "\n",
    "print(\"===================== Baseline Result =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE1, RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Solution\n",
    "(Put all your implementation for your solution in the following cell only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n",
    "# You are required to implement the existing solution in the given report here. \n",
    "# Then, evaluate your implementation by predicting the ratings in the test set (test_ds).\n",
    "# Finally, save the corresponding MAE and RMSE of your implementation \n",
    "# into the following defined corresponding variable. \n",
    "\n",
    "MAE = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
    "RMSE = 0 # 0 is an intial value, you need to update this with the actual perofrmance of your implementation.\n",
    "\n",
    "#we define the popularity significance weight of item t as per the formula \n",
    "weight1 = np.array(np.log(n_users/df.groupby('item_id').size()))\n",
    "\n",
    "def usernewfunction(imputed_train_ds,weight1):\n",
    "    '''\n",
    "    Function for calculating user's similarity\n",
    "    '''\n",
    "    active_user_pearson_corr = np.zeros((imputed_train_ds.shape[0], imputed_train_ds.shape[0]))\n",
    "\n",
    "    # Compute Pearson Correlation Coefficient of All Pairs of Users between active set and training dataset\n",
    "    for i, user_i_vec in enumerate(imputed_train_ds):\n",
    "        for j, user_j_vec in enumerate(imputed_train_ds):\n",
    "               \n",
    "            # ratings corated by the current pair of users\n",
    "            a_mask_i = user_i_vec > 0\n",
    "            u_mask_j = user_j_vec > 0\n",
    "\n",
    "            #Calculating the union set T(au) of the items voted by user a or user u\n",
    "            Tau = np.union1d(np.where(a_mask_i), np.where(u_mask_j))\n",
    "            \n",
    "            #For user a and u, finding the item set he hasnâ€™t rated in T(a,u)\n",
    "            Na = np.array(list(set(Tau) - set(np.where(a_mask_i)[0]))).astype(int)\n",
    "            Nu = np.array(list(set(Tau) - set(np.where(u_mask_j)[0]))).astype(int)\n",
    "            \n",
    "            #Use the result as the making up data, to overcome the sparsity problem\n",
    "            user_i_vec[Na] = np.round(np.average(user_i_vec[np.where(a_mask_i)]))\n",
    "            user_j_vec[Nu] = np.round(np.average(user_j_vec[np.where(u_mask_j)]))\n",
    "             \n",
    "            # corrated item index, skip if there are no corrated ratings\n",
    "            corrated_index = np.intersect1d(np.where(a_mask_i), np.where(u_mask_j))\n",
    "            if len(corrated_index) == 0:\n",
    "                continue\n",
    "                \n",
    "            # average value of user_i_vec and user_j_vec\n",
    "            mean_user_i = np.sum(user_i_vec) / (np.sum(np.clip(user_i_vec, 0, 1)) + EPSILON)\n",
    "            mean_user_j = np.sum(user_j_vec) / (np.sum(np.clip(user_j_vec, 0, 1)) + EPSILON)\n",
    "            \n",
    "            #we define the popularity significance weight of item t as per the formula \n",
    "            weight_final = weight1[corrated_index]\n",
    "            \n",
    "            # compute pearson corr\n",
    "            user_i_sub_mean = user_i_vec[corrated_index] - mean_user_i\n",
    "            user_j_sub_mean = user_j_vec[corrated_index] - mean_user_j\n",
    "\n",
    "            r_ui_sub_r_i_sq = np.square(user_i_sub_mean)*weight_final*weight_final\n",
    "            r_uj_sub_r_j_sq = np.square(user_j_sub_mean)*weight_final*weight_final\n",
    "\n",
    "            r_ui_sum_sqrt = np.sqrt(np.sum(r_ui_sub_r_i_sq))\n",
    "            r_uj_sum_sqrt = np.sqrt(np.sum(r_uj_sub_r_j_sq))\n",
    "\n",
    "            weighted_sim = np.sum(user_i_sub_mean * user_j_sub_mean*weight_final*weight_final) / (r_ui_sum_sqrt * r_uj_sum_sqrt + EPSILON)\n",
    "            active_user_pearson_corr[i][j] = weighted_sim\n",
    "\n",
    "    return active_user_pearson_corr\n",
    "\n",
    "user_pearson_corr = usernewfunction(train_ds,weight1)\n",
    "predicted_ds = predict(test_ds, train_ds, user_pearson_corr, k=20)\n",
    "MAE2, RMSE = evaluate(test_ds, predicted_ds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the MAE and RMSE of Your Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== The MAE and RMSE of Your Implementation =====================\n",
      "MAE: 0.7822435788080622, RMSE: 1.002498090002132\n"
     ]
    }
   ],
   "source": [
    "# Please don't change this cell\n",
    "\n",
    "print(\"===================== The MAE and RMSE of Your Implementation =====================\")\n",
    "print(\"MAE: {}, RMSE: {}\" .format(MAE2, RMSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAE Value for both the implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Implemented Solution</th>\n",
       "      <th>MAE Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>User_Corr</td>\n",
       "      <td>0.847171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>usernewfunction</td>\n",
       "      <td>0.782244</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Implemented Solution  MAE Value\n",
       "0            User_Corr   0.847171\n",
       "1      usernewfunction   0.782244"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [['User_Corr', MAE1], ['usernewfunction', MAE2]]\n",
    " \n",
    "# Create the pandas DataFrame\n",
    "df_final = pd.DataFrame(data, columns=['Implemented Solution', 'MAE Value'])\n",
    "df_final.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
