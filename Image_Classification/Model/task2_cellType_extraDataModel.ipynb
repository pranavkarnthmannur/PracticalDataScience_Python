{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "chnEF3kddbhw"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "# Extracting ZIP file for the images and CSV file\n",
        "with zipfile.ZipFile('/content/Image_classification_data.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('./')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "gYtax1Wwd2Wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "M1dzymoBlkU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "shfpW2ldhjSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_main = pd.read_csv('/content/data_labels_mainData.csv')\n",
        "data_main = data_main[['ImageName', 'cellType']]\n",
        "data_main.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vsIP7QRMlmXQ",
        "outputId": "62ff96f3-d38c-4b92-b2c2-47e259296051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ImageName  cellType\n",
              "0  22405.png         0\n",
              "1  22406.png         0\n",
              "2  22407.png         0\n",
              "3  22408.png         0\n",
              "4  22409.png         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a367e2dd-56f6-41b2-974e-1168f29cd32a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageName</th>\n",
              "      <th>cellType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>22405.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>22406.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22407.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22408.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22409.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a367e2dd-56f6-41b2-974e-1168f29cd32a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a367e2dd-56f6-41b2-974e-1168f29cd32a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a367e2dd-56f6-41b2-974e-1168f29cd32a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_main['cellType'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQEpgx4L9Jga",
        "outputId": "d73e3d10-5891-4987-9956-7347be2c9c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    4079\n",
              "1    2543\n",
              "0    1888\n",
              "3    1386\n",
              "Name: cellType, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_main['cellType'] = data_main['cellType'].astype('str')"
      ],
      "metadata": {
        "id": "mGGliZ2RloKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the Data"
      ],
      "metadata": {
        "id": "VMvGWk_2hqf2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting data into train, test and validation\n",
        "train_data, test_data = train_test_split(data_main, test_size=0.2, random_state=0)\n",
        "train_data, val_data = train_test_split(train_data, test_size=0.25, random_state=0)\n",
        "\n",
        "print(\"Train data : {}, Val Data: {}, Test Data: {}\".format(train_data.shape[0], val_data.shape[0], test_data.shape[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucPuQUDMltwf",
        "outputId": "245155ee-2249-4ba3-8f7c-e23a9ff5ff16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data : 5937, Val Data: 1979, Test Data: 1980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Performing data augmentation on train data to balance the binary classes**"
      ],
      "metadata": {
        "id": "VjGTrO9HSlr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/data_labels_mainData.csv')\n",
        "data = data[['ImageName', 'cellType']]\n"
      ],
      "metadata": {
        "id": "wPV2er71SomD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = train_test_split(data, test_size=0.1, random_state=42,stratify= data['cellType'])"
      ],
      "metadata": {
        "id": "mPKgw-L6TJEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "t2ShDffoa-N9",
        "outputId": "0061cb88-4944-46d0-89d1-1fe3976cc8e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ImageName  cellType\n",
              "856    9162.png         1\n",
              "9122  12135.png         2\n",
              "359     181.png         1\n",
              "8299   3653.png         2\n",
              "2645  18326.png         0\n",
              "...         ...       ...\n",
              "7491    674.png         0\n",
              "5832  19889.png         1\n",
              "9131  12147.png         2\n",
              "108   18872.png         1\n",
              "6846   4024.png         2\n",
              "\n",
              "[990 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-11651fa0-cfa3-45b7-9d31-1fe40c5020de\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageName</th>\n",
              "      <th>cellType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>856</th>\n",
              "      <td>9162.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9122</th>\n",
              "      <td>12135.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>181.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8299</th>\n",
              "      <td>3653.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2645</th>\n",
              "      <td>18326.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7491</th>\n",
              "      <td>674.png</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5832</th>\n",
              "      <td>19889.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9131</th>\n",
              "      <td>12147.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>18872.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6846</th>\n",
              "      <td>4024.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>990 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-11651fa0-cfa3-45b7-9d31-1fe40c5020de')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-11651fa0-cfa3-45b7-9d31-1fe40c5020de button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-11651fa0-cfa3-45b7-9d31-1fe40c5020de');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['cellType'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jiq_GfKmTSIK",
        "outputId": "b7d54a01-8f95-4d8a-e65d-a5da9c2c115f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    408\n",
              "1    254\n",
              "0    189\n",
              "3    139\n",
              "Name: cellType, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['cellType'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZbwSHkLTTEJ",
        "outputId": "2fd9ce25-e0f7-4d8b-a55a-973c6b90be40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    3671\n",
              "1    2289\n",
              "0    1699\n",
              "3    1247\n",
              "Name: cellType, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train_data"
      ],
      "metadata": {
        "id": "9JlePI7JVRc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "z_Gulp2gWJb7",
        "outputId": "ba397f1d-c0ac-4504-fa7b-230df31b2f29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ImageName  cellType\n",
              "1702  13444.png         1\n",
              "4611  16714.png         3\n",
              "5790  19846.png         1\n",
              "6982   1294.png         3\n",
              "5423  11785.png         2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-010a138a-33f0-48ec-aff5-dfef4e1e47c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageName</th>\n",
              "      <th>cellType</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1702</th>\n",
              "      <td>13444.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611</th>\n",
              "      <td>16714.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5790</th>\n",
              "      <td>19846.png</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6982</th>\n",
              "      <td>1294.png</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5423</th>\n",
              "      <td>11785.png</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-010a138a-33f0-48ec-aff5-dfef4e1e47c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-010a138a-33f0-48ec-aff5-dfef4e1e47c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-010a138a-33f0-48ec-aff5-dfef4e1e47c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming you have a DataFrame called 'df' with columns 'ImageName' and 'Class'\n",
        "\n",
        "# Group the DataFrame by 'Class'\n",
        "grouped_df = train_data.groupby('cellType')\n",
        "\n",
        "# Create empty dictionaries to store the separated DataFrames\n",
        "class_dfs = {}\n",
        "\n",
        "# Iterate over the groups and create separate DataFrames for each class\n",
        "for class_label, group in grouped_df:\n",
        "    class_dfs[class_label] = group.drop('cellType', axis=1).copy()\n",
        "\n",
        "# Access the separated DataFrames using the class label as the key\n",
        "class0_df = class_dfs[0]\n",
        "class1_df = class_dfs[1]\n",
        "class2_df = class_dfs[2]\n",
        "class3_df = class_dfs[3]"
      ],
      "metadata": {
        "id": "Ln4Yik3ycwMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data augmentation"
      ],
      "metadata": {
        "id": "Nr2MSv9RVAkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# all the augmented images are stored in different floder so moving those folders into one folder \n",
        "\n",
        "import shutil\n",
        "\n",
        "def move_augmented_files(source_dir, destination_dir):\n",
        "    os.makedirs(destination_dir, exist_ok=True)\n",
        "\n",
        "    for file_name in os.listdir(source_dir):\n",
        "        if file_name.startswith(\"augmented\"):\n",
        "            source_path = os.path.join(source_dir, file_name)\n",
        "            destination_path = os.path.join(destination_dir, file_name)\n",
        "            shutil.move(source_path, destination_path)"
      ],
      "metadata": {
        "id": "Qwx4SsVrkleF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def augment_data(df, output_dir, num_augmentations=1):\n",
        "    datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "    augmented_image_paths = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        image_name = row['ImageName']\n",
        "        image_path = os.path.join(image_base_folder, image_name)\n",
        "\n",
        "        # Load the image\n",
        "        img = Image.open(image_path)\n",
        "        img = img.resize((27, 27))\n",
        "\n",
        "        # Get the file name without extension\n",
        "        file_name = os.path.splitext(image_name)[0]\n",
        "\n",
        "        # Perform data augmentation\n",
        "        img_arr = np.array(img)\n",
        "        img_arr = np.expand_dims(img_arr, axis=0)  # Add batch dimension for data generator\n",
        "\n",
        "        datagen.fit(img_arr)\n",
        "\n",
        "        augmented_image_name = f\"augmented_{os.path.splitext(os.path.basename(image_path))[0]}.png\"\n",
        "        augmented_image_path = os.path.join(output_dir, augmented_image_name)\n",
        "\n",
        "        for i, batch in enumerate(datagen.flow(img_arr, batch_size=1, save_to_dir=output_dir, save_prefix='', save_format='png')):\n",
        "            augmented_image_temp_path = os.path.join(output_dir, f\"temp_augmented_{i}.png\")\n",
        "            Image.fromarray(batch[0].astype(np.uint8)).save(augmented_image_temp_path)\n",
        "            os.rename(augmented_image_temp_path, augmented_image_path)\n",
        "            augmented_image_paths.append(augmented_image_path)\n",
        "            break  # Generate only one augmented image per original image\n",
        "\n",
        "            if i >= num_augmentations - 1:\n",
        "                break  # Stop after generating the specified number of augmented images\n",
        "\n",
        "    return augmented_image_paths\n",
        "\n",
        "# Define your DataFrame 'df' with the 'ImageName' column\n",
        " \n",
        "# Determine the number of augmented images to create based on the multiplier\n"
      ],
      "metadata": {
        "id": "qJC31kpOVF4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## class 0 "
      ],
      "metadata": {
        "id": "PD86G8JOylmF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the base path to the folder containing the images\n",
        "image_base_folder = \"/content/patch_images\"\n",
        "\n",
        "# Define the paths to the augmented dataset\n",
        "augmented_dir = \"/content/augmented_dataset10\"\n",
        "augmented_image_dir = os.path.join(augmented_dir)\n",
        "\n",
        "# Create the augmented dataset directories if they don't exist\n",
        "os.makedirs(augmented_image_dir, exist_ok=True)\n",
        "# Data augmentation parameters\n",
        "\n",
        "\n",
        "multiplier = 2  # Set the desired augmentation factor\n",
        "num_augmentations = len(class0_df) * multiplier\n",
        "\n",
        "# Perform data augmentation and get the augmented image names\n",
        "augmented_image_paths = augment_data(class0_df, augmented_dir, num_augmentations)\n",
        "\n",
        "# Update the 'ImageName' column with augmented image names\n",
        "augmented_df = pd.DataFrame({'ImageName': [os.path.basename(image_path) for image_path in augmented_image_paths]})\n",
        "\n",
        "# Concatenate the augmented DataFrame with the original majority class DataFrame\n",
        "\n",
        "# Update the original DataFrame with the augmented image names and class labels\n",
        "class0_df  = pd.concat([class0_df, augmented_df], ignore_index=True)\n",
        "\n",
        "move_augmented_files(augmented_dir, image_base_folder)"
      ],
      "metadata": {
        "id": "Bq9X8krAxzl_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multiplier = 2  # Set the desired augmentation factor\n",
        "num_augmentations = len(class0_df) * multiplier\n",
        "\n",
        "# Perform data augmentation and get the augmented image names\n",
        "augmented_image_paths = augment_data(class0_df, augmented_dir, num_augmentations)\n",
        "\n",
        "# Update the 'ImageName' column with augmented image names\n",
        "augmented_df = pd.DataFrame({'ImageName': [os.path.basename(image_path) for image_path in augmented_image_paths]})\n",
        "\n",
        "# Concatenate the augmented DataFrame with the original majority class DataFrame\n",
        "\n",
        "# Update the original DataFrame with the augmented image names and class labels\n",
        "class0_df  = pd.concat([class0_df, augmented_df], ignore_index=True)\n",
        "\n",
        "move_augmented_files(augmented_dir, image_base_folder)"
      ],
      "metadata": {
        "id": "ssJeE8LAxSvN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class 1"
      ],
      "metadata": {
        "id": "IKdSbP46yr0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multiplier = 2  # Set the desired augmentation factor\n",
        "num_augmentations = len(class1_df) * multiplier\n",
        "\n",
        "# Perform data augmentation and get the augmented image names\n",
        "augmented_image_paths = augment_data(class1_df, augmented_dir, num_augmentations)\n",
        "\n",
        "# Update the 'ImageName' column with augmented image names\n",
        "augmented_df = pd.DataFrame({'ImageName': [os.path.basename(image_path) for image_path in augmented_image_paths]})\n",
        "\n",
        "# Concatenate the augmented DataFrame with the original majority class DataFrame\n",
        "\n",
        "# Update the original DataFrame with the augmented image names and class labels\n",
        "class1_1_df  = pd.concat([class1_df, augmented_df], ignore_index=True)\n",
        "\n",
        "move_augmented_files(augmented_dir, image_base_folder)"
      ],
      "metadata": {
        "id": "SojsXW_iyv4H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class1_df  = pd.concat([class1_df, class1_1_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "-dH8N7bqzBUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class 2"
      ],
      "metadata": {
        "id": "7vkJOkYXzKyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multiplier = 2  # Set the desired augmentation factor\n",
        "num_augmentations = len(class2_df) * multiplier\n",
        "\n",
        "# Perform data augmentation and get the augmented image names\n",
        "augmented_image_paths = augment_data(class2_df, augmented_dir, num_augmentations)\n",
        "\n",
        "# Update the 'ImageName' column with augmented image names\n",
        "augmented_df = pd.DataFrame({'ImageName': [os.path.basename(image_path) for image_path in augmented_image_paths]})\n",
        "\n",
        "# Concatenate the augmented DataFrame with the original majority class DataFrame\n",
        "\n",
        "# Update the original DataFrame with the augmented image names and class labels\n",
        "class2_df  = pd.concat([class2_df, augmented_df], ignore_index=True)\n",
        "\n",
        "move_augmented_files(augmented_dir, image_base_folder)"
      ],
      "metadata": {
        "id": "XWA89QG_zM24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Class 3"
      ],
      "metadata": {
        "id": "M2v9N29M4fVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multiplier = 2  # Set the desired augmentation factor\n",
        "num_augmentations = len(class3_df) * multiplier\n",
        "\n",
        "# Perform data augmentation and get the augmented image names\n",
        "augmented_image_paths = augment_data(class3_df, augmented_dir, num_augmentations)\n",
        "\n",
        "# Update the 'ImageName' column with augmented image names\n",
        "augmented_df = pd.DataFrame({'ImageName': [os.path.basename(image_path) for image_path in augmented_image_paths]})\n",
        "\n",
        "# Concatenate the augmented DataFrame with the original majority class DataFrame\n",
        "\n",
        "# Update the original DataFrame with the augmented image names and class labels\n",
        "class3_3_df  = pd.concat([class3_df, augmented_df], ignore_index=True)\n",
        "\n",
        "move_augmented_files(augmented_dir, image_base_folder)"
      ],
      "metadata": {
        "id": "dAT0AwKmzVu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multiplier = 2  # Set the desired augmentation factor\n",
        "num_augmentations = len(class3_3_df) * multiplier\n",
        "\n",
        "# Perform data augmentation and get the augmented image names\n",
        "augmented_image_paths = augment_data(class3_3_df, augmented_dir, num_augmentations)\n",
        "\n",
        "# Update the 'ImageName' column with augmented image names\n",
        "augmented_df = pd.DataFrame({'ImageName': [os.path.basename(image_path) for image_path in augmented_image_paths]})\n",
        "\n",
        "# Concatenate the augmented DataFrame with the original majority class DataFrame\n",
        "\n",
        "# Update the original DataFrame with the augmented image names and class labels\n",
        "class3_3_3_df  = pd.concat([class3_3_df, augmented_df], ignore_index=True)\n",
        "\n",
        "move_augmented_files(augmented_dir, image_base_folder)"
      ],
      "metadata": {
        "id": "p0kUh27zzcbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class3_df  = pd.concat([class3_3_3_df, class3_df], ignore_index=True)"
      ],
      "metadata": {
        "id": "QPPRIvN5zy-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class0_df['cellType'] = '0'\n",
        "class1_df['cellType'] = '1'\n",
        "class2_df['cellType'] = '2'\n",
        "class3_df['cellType'] = '3'\n",
        "\n",
        "merged_df = pd.concat([class0_df, class1_df, class2_df, class3_df], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "rLC9c2G51rgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['cellType'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFaohU42mcqe",
        "outputId": "3f09c080-f75c-42ac-c82e-1eac13c4bdf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    7342\n",
              "1    6867\n",
              "0    6796\n",
              "3    6235\n",
              "Name: cellType, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_test_split(merged_df, test_size=0.10, random_state=0)\n",
        "# Converting the data labels to string\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Real time data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
        "val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_generator_2 = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_data,\n",
        "        directory='/content/patch_images',\n",
        "        x_col=\"ImageName\",\n",
        "        y_col=\"cellType\",\n",
        "        target_size=(27, 27),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "valid_generator_2 = val_datagen.flow_from_dataframe(\n",
        "        dataframe=val_data,\n",
        "        directory='/content/patch_images',\n",
        "        x_col=\"ImageName\",\n",
        "        y_col=\"cellType\",\n",
        "        target_size=(27, 27),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "# test data generator for evaluating the performance of a previously trained model on a test dataset\n",
        "test_data['cellType'] = test_data['cellType'].astype('str')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "test_generator_2 = test_datagen.flow_from_dataframe(\n",
        "        dataframe=test_data,\n",
        "        directory='/content/patch_images',\n",
        "        x_col=\"ImageName\",\n",
        "        y_col=\"cellType\",\n",
        "        target_size=(27, 27),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "n3K3PvB748jK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3fb172-3e5f-4097-9cba-8f3619ed17f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 24516 validated image filenames belonging to 4 classes.\n",
            "Found 2724 validated image filenames belonging to 4 classes.\n",
            "Found 990 validated image filenames belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Extra Data Set to Improve Accuracy "
      ],
      "metadata": {
        "id": "OoIL1CHrvyN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "\n",
        "best_model = keras.models.load_model('best_model.h5')"
      ],
      "metadata": {
        "id": "hnrifnP3v10e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Make predictions on the test generator\n",
        "y_pred_prob = best_model.predict(test_generator_2)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Get true labels from the test generator\n",
        "y_true = test_generator_2.classes\n",
        "\n",
        "# Filter y_pred_prob based on correct predictions\n",
        "correct_predictions = np.equal(y_pred, y_true)\n",
        "y_pred_prob_correct = y_pred_prob[correct_predictions]\n",
        "\n",
        "# Calculate the mean of predicted probabilities for correct predictions\n",
        "y_pred_prob_mean = np.median(y_pred_prob_correct, axis=0)  # Mean along axis 0\n",
        "\n",
        "# Generate classification report\n",
        "class_names = list(test_generator_2.class_indices.keys())\n",
        "report = classification_report(y_true, y_pred, target_names=class_names)\n",
        "\n",
        "print(report)\n",
        "print(\"Median of predicted probabilities for correct predictions:\")\n",
        "for class_idx, class_name in enumerate(class_names):\n",
        "    print(f\"{class_name}: {y_pred_prob_mean[class_idx]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTi7FJKXxzw8",
        "outputId": "8e79c854-ccd8-4ddf-8479-6ddb2d3c07e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 0s 12ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.08      0.09       189\n",
            "           1       0.28      0.35      0.31       254\n",
            "           2       0.42      0.41      0.42       408\n",
            "           3       0.13      0.12      0.12       139\n",
            "\n",
            "    accuracy                           0.29       990\n",
            "   macro avg       0.23      0.24      0.23       990\n",
            "weighted avg       0.28      0.29      0.29       990\n",
            "\n",
            "Median of predicted probabilities for correct predictions:\n",
            "0: 0.040538571774959564\n",
            "1: 0.0181454885751009\n",
            "2: 0.7139264941215515\n",
            "3: 0.0664956271648407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_extra = pd.read_csv('/content/data_labels_extraData.csv')\n",
        "data_extra = data[['ImageName']]"
      ],
      "metadata": {
        "id": "OEc4MQrBx5-v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "test_new_data_generator = test_datagen.flow_from_dataframe(\n",
        "        dataframe=data_extra,\n",
        "        directory='/content/patch_images',\n",
        "        x_col=\"ImageName\",\n",
        "        y_col=None,\n",
        "        target_size=(27, 27),\n",
        "        batch_size=batch_size,\n",
        "        class_mode=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0RYH04RzZa6",
        "outputId": "8e10442c-48a8-4805-9b71-9602560e9475"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 9896 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Make predictions on the validation generator\n",
        "y_pred_prob = best_model.predict(test_generator_2)\n",
        "\n",
        "# Convert predicted probabilities to class labels\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Get true labels from the validation generator\n",
        "y_true = test_generator_2.classes\n",
        "\n",
        "# Filter y_pred_prob based on correct predictions\n",
        "correct_predictions = np.equal(y_pred, y_true)\n",
        "y_pred_prob_correct = y_pred_prob[correct_predictions]\n",
        "\n",
        "# Calculate the median of predicted probabilities for correct predictions\n",
        "class_medians = np.mean(y_pred_prob_correct, axis=0)\n",
        "\n",
        "# For new unseen data, obtain predicted probabilities from the model\n",
        "new_pred_prob = best_model.predict(test_new_data_generator)\n",
        "\n",
        "# Calculate distances between predicted probabilities and median values\n",
        "distances = np.abs(new_pred_prob - class_medians)\n",
        "\n",
        "# Assign new unseen data to the class with the closest median value (smallest distance)\n",
        "predicted_classes = np.argmin(distances, axis=1)\n",
        "\n",
        "# Get the indices of the new data\n",
        "new_data_indices = test_new_data_generator.index_array\n",
        "\n",
        "# Create a DataFrame to store the data indices and their predicted classes\n",
        "data_with_predictions = pd.DataFrame({'ImageName': data_extra['ImageName'], 'PredictedClass': np.nan})\n",
        "\n",
        "# Populate the DataFrame with the data indices and predicted classes\n",
        "data_with_predictions.loc[new_data_indices, 'PredictedClass'] = predicted_classes\n",
        "\n",
        "# Print the DataFrame with predicted classes\n",
        "print(data_with_predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lyjP5C0zbKG",
        "outputId": "99b8dd3f-ad27-4cf9-d342-16e934de09fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 0s 11ms/step\n",
            "310/310 [==============================] - 3s 11ms/step\n",
            "      ImageName  PredictedClass\n",
            "0     22405.png               3\n",
            "1     22406.png               1\n",
            "2     22407.png               0\n",
            "3     22408.png               0\n",
            "4     22409.png               0\n",
            "...         ...             ...\n",
            "9891   1625.png               0\n",
            "9892   1626.png               0\n",
            "9893   1627.png               3\n",
            "9894   1628.png               0\n",
            "9895   1629.png               3\n",
            "\n",
            "[9896 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-107-4b20e0613704>:36: DeprecationWarning: In a future version, `df.iloc[:, i] = newvals` will attempt to set the values inplace instead of always setting a new array. To retain the old behavior, use either `df[df.columns[i]] = newvals` or, if columns are non-unique, `df.isetitem(i, newvals)`\n",
            "  data_with_predictions.loc[new_data_indices, 'PredictedClass'] = predicted_classes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_predictions.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oA_flcTG0elp",
        "outputId": "54998de0-448e-42fb-da1e-476ff0bda784"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9896 entries, 0 to 9895\n",
            "Data columns (total 2 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   ImageName       9896 non-null   object\n",
            " 1   PredictedClass  9896 non-null   int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 154.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_predictions = data_with_predictions.rename(columns={\"PredictedClass\": \"cellType\"})\n"
      ],
      "metadata": {
        "id": "_FHfAfJc-EEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_with_predictions[\"cellType\"] = data_with_predictions[\"cellType\"].astype(str)"
      ],
      "metadata": {
        "id": "FSLMoQuD-URH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data = train_test_split(data_with_predictions, test_size=0.10, random_state=0)\n",
        "# Converting the data labels to string\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Real time data augmentation\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
        "val_datagen = ImageDataGenerator(rescale=1./255, data_format='channels_last')\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_generator_new = train_datagen.flow_from_dataframe(\n",
        "        dataframe=train_data,\n",
        "        directory='/content/patch_images',\n",
        "        x_col=\"ImageName\",\n",
        "        y_col=\"cellType\",\n",
        "        target_size=(27, 27),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n",
        "valid_generator_new = val_datagen.flow_from_dataframe(\n",
        "        dataframe=val_data,\n",
        "        directory='/content/patch_images',\n",
        "        x_col=\"ImageName\",\n",
        "        y_col=\"cellType\",\n",
        "        target_size=(27, 27),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Irvft-s1_EOr",
        "outputId": "e9c31013-cd02-44b7-915b-cb816d55dab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8906 validated image filenames belonging to 4 classes.\n",
            "Found 990 validated image filenames belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "optimizer = SGD(learning_rate=learning_rate, momentum=0.9)\n",
        "\n",
        "# Compile the model\n",
        "best_model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define the model checkpoint callback\n",
        "checkpoint = ModelCheckpoint('best_model_new.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "\n",
        "# Train the model and save the best model based on validation accuracy\n",
        "best_model.fit(train_generator_new, epochs=51, validation_data=valid_generator_new, callbacks=[checkpoint])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et24CKTF_Pj8",
        "outputId": "af3c9d00-ad6b-4ee2-c8ea-69a5a5ac4a35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 1.0476 - accuracy: 0.5095\n",
            "Epoch 1: val_accuracy improved from -inf to 0.51212, saving model to best_model_new.h5\n",
            "279/279 [==============================] - 7s 19ms/step - loss: 1.0484 - accuracy: 0.5083 - val_loss: 1.0228 - val_accuracy: 0.5121\n",
            "Epoch 2/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 1.0181 - accuracy: 0.5173\n",
            "Epoch 2: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 4s 16ms/step - loss: 1.0181 - accuracy: 0.5173 - val_loss: 1.0257 - val_accuracy: 0.5121\n",
            "Epoch 3/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 1.0180 - accuracy: 0.5167\n",
            "Epoch 3: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 5s 19ms/step - loss: 1.0183 - accuracy: 0.5164 - val_loss: 1.0218 - val_accuracy: 0.5121\n",
            "Epoch 4/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 1.0157 - accuracy: 0.5166\n",
            "Epoch 4: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 4s 15ms/step - loss: 1.0164 - accuracy: 0.5164 - val_loss: 1.0239 - val_accuracy: 0.5121\n",
            "Epoch 5/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 1.0161 - accuracy: 0.5158\n",
            "Epoch 5: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 4s 16ms/step - loss: 1.0152 - accuracy: 0.5164 - val_loss: 1.0218 - val_accuracy: 0.5121\n",
            "Epoch 6/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 1.0134 - accuracy: 0.5164\n",
            "Epoch 6: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 5s 19ms/step - loss: 1.0134 - accuracy: 0.5164 - val_loss: 1.0198 - val_accuracy: 0.5121\n",
            "Epoch 7/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 1.0127 - accuracy: 0.5164\n",
            "Epoch 7: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 4s 15ms/step - loss: 1.0127 - accuracy: 0.5164 - val_loss: 1.0210 - val_accuracy: 0.5121\n",
            "Epoch 8/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 1.0109 - accuracy: 0.5163\n",
            "Epoch 8: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 5s 16ms/step - loss: 1.0110 - accuracy: 0.5164 - val_loss: 1.0198 - val_accuracy: 0.5121\n",
            "Epoch 9/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 1.0108 - accuracy: 0.5166\n",
            "Epoch 9: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 5s 17ms/step - loss: 1.0109 - accuracy: 0.5164 - val_loss: 1.0234 - val_accuracy: 0.5121\n",
            "Epoch 10/51\n",
            "275/279 [============================>.] - ETA: 0s - loss: 1.0097 - accuracy: 0.5159\n",
            "Epoch 10: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 4s 16ms/step - loss: 1.0085 - accuracy: 0.5164 - val_loss: 1.0239 - val_accuracy: 0.5121\n",
            "Epoch 11/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 1.0067 - accuracy: 0.5163\n",
            "Epoch 11: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 5s 18ms/step - loss: 1.0067 - accuracy: 0.5163 - val_loss: 1.0320 - val_accuracy: 0.5121\n",
            "Epoch 12/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 1.0093 - accuracy: 0.5165\n",
            "Epoch 12: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 5s 16ms/step - loss: 1.0086 - accuracy: 0.5163 - val_loss: 1.0217 - val_accuracy: 0.5121\n",
            "Epoch 13/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 1.0054 - accuracy: 0.5163\n",
            "Epoch 13: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 5s 18ms/step - loss: 1.0057 - accuracy: 0.5165 - val_loss: 1.0242 - val_accuracy: 0.5121\n",
            "Epoch 14/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 1.0049 - accuracy: 0.5158\n",
            "Epoch 14: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 4s 15ms/step - loss: 1.0045 - accuracy: 0.5163 - val_loss: 1.0355 - val_accuracy: 0.5121\n",
            "Epoch 15/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 1.0041 - accuracy: 0.5166\n",
            "Epoch 15: val_accuracy did not improve from 0.51212\n",
            "279/279 [==============================] - 5s 18ms/step - loss: 1.0041 - accuracy: 0.5164 - val_loss: 1.0255 - val_accuracy: 0.5121\n",
            "Epoch 16/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 1.0021 - accuracy: 0.5162\n",
            "Epoch 16: val_accuracy improved from 0.51212 to 0.51313, saving model to best_model_new.h5\n",
            "279/279 [==============================] - 4s 16ms/step - loss: 1.0016 - accuracy: 0.5166 - val_loss: 1.0277 - val_accuracy: 0.5131\n",
            "Epoch 17/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 1.0008 - accuracy: 0.5163\n",
            "Epoch 17: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 15ms/step - loss: 1.0006 - accuracy: 0.5162 - val_loss: 1.0316 - val_accuracy: 0.5121\n",
            "Epoch 18/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 0.9982 - accuracy: 0.5165\n",
            "Epoch 18: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 19ms/step - loss: 0.9980 - accuracy: 0.5159 - val_loss: 1.0279 - val_accuracy: 0.5121\n",
            "Epoch 19/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 0.9948 - accuracy: 0.5161\n",
            "Epoch 19: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 16ms/step - loss: 0.9945 - accuracy: 0.5167 - val_loss: 1.0275 - val_accuracy: 0.5121\n",
            "Epoch 20/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 0.9914 - accuracy: 0.5166\n",
            "Epoch 20: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 17ms/step - loss: 0.9921 - accuracy: 0.5163 - val_loss: 1.0421 - val_accuracy: 0.5121\n",
            "Epoch 21/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 0.9939 - accuracy: 0.5178\n",
            "Epoch 21: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 17ms/step - loss: 0.9931 - accuracy: 0.5172 - val_loss: 1.0280 - val_accuracy: 0.5081\n",
            "Epoch 22/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 0.9882 - accuracy: 0.5165\n",
            "Epoch 22: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 16ms/step - loss: 0.9880 - accuracy: 0.5166 - val_loss: 1.0333 - val_accuracy: 0.5121\n",
            "Epoch 23/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 0.9881 - accuracy: 0.5144\n",
            "Epoch 23: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 18ms/step - loss: 0.9881 - accuracy: 0.5141 - val_loss: 1.0343 - val_accuracy: 0.5121\n",
            "Epoch 24/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 0.9813 - accuracy: 0.5140\n",
            "Epoch 24: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 15ms/step - loss: 0.9813 - accuracy: 0.5148 - val_loss: 1.0485 - val_accuracy: 0.5121\n",
            "Epoch 25/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 0.9863 - accuracy: 0.5156\n",
            "Epoch 25: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 16ms/step - loss: 0.9863 - accuracy: 0.5156 - val_loss: 1.0249 - val_accuracy: 0.5131\n",
            "Epoch 26/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 0.9773 - accuracy: 0.5156\n",
            "Epoch 26: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 17ms/step - loss: 0.9763 - accuracy: 0.5158 - val_loss: 1.0545 - val_accuracy: 0.5030\n",
            "Epoch 27/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 0.9747 - accuracy: 0.5169\n",
            "Epoch 27: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 16ms/step - loss: 0.9742 - accuracy: 0.5177 - val_loss: 1.0578 - val_accuracy: 0.5121\n",
            "Epoch 28/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 0.9663 - accuracy: 0.5156\n",
            "Epoch 28: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 19ms/step - loss: 0.9663 - accuracy: 0.5156 - val_loss: 1.0708 - val_accuracy: 0.5061\n",
            "Epoch 29/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 0.9622 - accuracy: 0.5136\n",
            "Epoch 29: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 15ms/step - loss: 0.9622 - accuracy: 0.5136 - val_loss: 1.0524 - val_accuracy: 0.5131\n",
            "Epoch 30/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 0.9591 - accuracy: 0.5166\n",
            "Epoch 30: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 16ms/step - loss: 0.9587 - accuracy: 0.5168 - val_loss: 1.0482 - val_accuracy: 0.5121\n",
            "Epoch 31/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 0.9524 - accuracy: 0.5211\n",
            "Epoch 31: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 16ms/step - loss: 0.9521 - accuracy: 0.5210 - val_loss: 1.0967 - val_accuracy: 0.4778\n",
            "Epoch 32/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 0.9464 - accuracy: 0.5228\n",
            "Epoch 32: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 15ms/step - loss: 0.9464 - accuracy: 0.5228 - val_loss: 1.0779 - val_accuracy: 0.4949\n",
            "Epoch 33/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 0.9450 - accuracy: 0.5193\n",
            "Epoch 33: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 19ms/step - loss: 0.9446 - accuracy: 0.5204 - val_loss: 1.0883 - val_accuracy: 0.4980\n",
            "Epoch 34/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 0.9373 - accuracy: 0.5201\n",
            "Epoch 34: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 16ms/step - loss: 0.9367 - accuracy: 0.5207 - val_loss: 1.1102 - val_accuracy: 0.5091\n",
            "Epoch 35/51\n",
            "275/279 [============================>.] - ETA: 0s - loss: 0.9369 - accuracy: 0.5236\n",
            "Epoch 35: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 16ms/step - loss: 0.9365 - accuracy: 0.5236 - val_loss: 1.1033 - val_accuracy: 0.4737\n",
            "Epoch 36/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 0.9215 - accuracy: 0.5234\n",
            "Epoch 36: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 16ms/step - loss: 0.9215 - accuracy: 0.5235 - val_loss: 1.0754 - val_accuracy: 0.4909\n",
            "Epoch 37/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 0.9133 - accuracy: 0.5326\n",
            "Epoch 37: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 18ms/step - loss: 0.9133 - accuracy: 0.5326 - val_loss: 1.1469 - val_accuracy: 0.5051\n",
            "Epoch 38/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 0.9103 - accuracy: 0.5292\n",
            "Epoch 38: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 17ms/step - loss: 0.9106 - accuracy: 0.5293 - val_loss: 1.1176 - val_accuracy: 0.4909\n",
            "Epoch 39/51\n",
            "275/279 [============================>.] - ETA: 0s - loss: 0.9078 - accuracy: 0.5375\n",
            "Epoch 39: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 16ms/step - loss: 0.9076 - accuracy: 0.5374 - val_loss: 1.1349 - val_accuracy: 0.4889\n",
            "Epoch 40/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 0.8993 - accuracy: 0.5388\n",
            "Epoch 40: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 19ms/step - loss: 0.8991 - accuracy: 0.5395 - val_loss: 1.1687 - val_accuracy: 0.4626\n",
            "Epoch 41/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 0.8860 - accuracy: 0.5405\n",
            "Epoch 41: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 15ms/step - loss: 0.8854 - accuracy: 0.5414 - val_loss: 1.2366 - val_accuracy: 0.4495\n",
            "Epoch 42/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 0.8667 - accuracy: 0.5440\n",
            "Epoch 42: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 17ms/step - loss: 0.8667 - accuracy: 0.5440 - val_loss: 1.2676 - val_accuracy: 0.4960\n",
            "Epoch 43/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 0.8614 - accuracy: 0.5511\n",
            "Epoch 43: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 16ms/step - loss: 0.8614 - accuracy: 0.5511 - val_loss: 1.2442 - val_accuracy: 0.4535\n",
            "Epoch 44/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 0.8511 - accuracy: 0.5615\n",
            "Epoch 44: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 17ms/step - loss: 0.8511 - accuracy: 0.5615 - val_loss: 1.2476 - val_accuracy: 0.4697\n",
            "Epoch 45/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 0.8483 - accuracy: 0.5622\n",
            "Epoch 45: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 6s 20ms/step - loss: 0.8501 - accuracy: 0.5615 - val_loss: 1.1576 - val_accuracy: 0.5071\n",
            "Epoch 46/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 0.8600 - accuracy: 0.5604\n",
            "Epoch 46: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 16ms/step - loss: 0.8600 - accuracy: 0.5604 - val_loss: 1.1380 - val_accuracy: 0.4737\n",
            "Epoch 47/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 0.8321 - accuracy: 0.5721\n",
            "Epoch 47: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 17ms/step - loss: 0.8321 - accuracy: 0.5720 - val_loss: 1.1866 - val_accuracy: 0.4596\n",
            "Epoch 48/51\n",
            "276/279 [============================>.] - ETA: 0s - loss: 0.8308 - accuracy: 0.5688\n",
            "Epoch 48: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 16ms/step - loss: 0.8298 - accuracy: 0.5697 - val_loss: 1.2460 - val_accuracy: 0.4667\n",
            "Epoch 49/51\n",
            "279/279 [==============================] - ETA: 0s - loss: 0.8296 - accuracy: 0.5688\n",
            "Epoch 49: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 4s 16ms/step - loss: 0.8296 - accuracy: 0.5688 - val_loss: 1.2646 - val_accuracy: 0.4707\n",
            "Epoch 50/51\n",
            "278/279 [============================>.] - ETA: 0s - loss: 0.8204 - accuracy: 0.5708\n",
            "Epoch 50: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 19ms/step - loss: 0.8205 - accuracy: 0.5705 - val_loss: 1.1292 - val_accuracy: 0.4778\n",
            "Epoch 51/51\n",
            "277/279 [============================>.] - ETA: 0s - loss: 0.8223 - accuracy: 0.5732\n",
            "Epoch 51: val_accuracy did not improve from 0.51313\n",
            "279/279 [==============================] - 5s 17ms/step - loss: 0.8222 - accuracy: 0.5731 - val_loss: 1.2431 - val_accuracy: 0.4889\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e66ef9390>"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# Make predictions using the model on the generator data\n",
        "# Make predictions using the model on the generator data\n",
        "# Make predictions using the model on the generator data\n",
        "y_pred_prob = best_model.predict(test_generator_2)\n",
        "y_pred = np.argmax(y_pred_prob, axis=1)\n",
        "\n",
        "# Concatenate true labels from the generator data\n",
        "y_true = np.concatenate([test_generator_2[i][1] for i in range(len(test_generator_2))])\n",
        "y_true = np.argmax(y_true, axis=1)\n",
        "\n",
        "# Print the true class labels, predicted probabilities, and predicted class labels side by side\n",
        "# Convert true labels to multilabel-indicator format if necessary\n",
        "\n",
        "# Compute the classification report\n",
        "report = classification_report(y_true, y_pred)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-H7r3JmMBEHi",
        "outputId": "082b88a1-9233-43e4-f1d2-41c9427722f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 0s 10ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.19      0.82      0.31       189\n",
            "           1       0.28      0.07      0.12       254\n",
            "           2       0.00      0.00      0.00       408\n",
            "           3       0.13      0.11      0.12       139\n",
            "\n",
            "    accuracy                           0.19       990\n",
            "   macro avg       0.15      0.25      0.14       990\n",
            "weighted avg       0.13      0.19      0.11       990\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YX6vFrNmA5mw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}